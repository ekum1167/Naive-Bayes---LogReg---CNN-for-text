{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project03_CNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6eLdVBED4dl"
      },
      "source": [
        "import os\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4E6rNd6D6ti"
      },
      "source": [
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kitasxMDzmt"
      },
      "source": [
        "# DOWNLOAD LINKS\r\n",
        "import pandas as pd\r\n",
        "link_train = 'https://drive.google.com/file/d/1JlCy6JQ5y6gBcMooJdMaWwc8XeMVIf52/view?usp=sharing'\r\n",
        "\r\n",
        "download = drive.CreateFile({'id': '1JlCy6JQ5y6gBcMooJdMaWwc8XeMVIf52'})\r\n",
        "download.GetContentFile('train.csv')\r\n",
        "\r\n",
        "df_train = pd.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ8WPtOSEDYi"
      },
      "source": [
        "link_test = 'https://drive.google.com/file/d/1OrC0aelyv_Av90a5-PrmbaEquPRDmYP1/view?usp=sharing'\r\n",
        "\r\n",
        "\r\n",
        "download_test = drive.CreateFile({'id': '1OrC0aelyv_Av90a5-PrmbaEquPRDmYP1'})\r\n",
        "download_test.GetContentFile('test.csv')\r\n",
        "\r\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGxJDg7qELoz"
      },
      "source": [
        "X_train = df_train.text\r\n",
        "y_train = df_train.label\r\n",
        "\r\n",
        "X_test = df_test.text\r\n",
        "y_test = df_test.label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WNUfkINLlpX",
        "outputId": "bd0789d7-b584-4ea8-cb71-c62dd727940b"
      },
      "source": [
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0          video\n",
            "1          dunya\n",
            "2          video\n",
            "3          video\n",
            "4       yazarlar\n",
            "          ...   \n",
            "1995        spor\n",
            "1996       dunya\n",
            "1997     turkiye\n",
            "1998    yazarlar\n",
            "1999        spor\n",
            "Name: label, Length: 2000, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3dx9QFvLhfP"
      },
      "source": [
        "#ONE HOT ENCODING\r\n",
        "\r\n",
        "import numpy \r\n",
        "y_train_num = []\r\n",
        "for label in y_train:\r\n",
        "    if label == 'spor':\r\n",
        "        y_train_num.append([0,0,0,0,1])\r\n",
        "    elif label == 'dunya':\r\n",
        "        y_train_num.append([0,0,0,1,0])\r\n",
        "    elif label == 'yazarlar':\r\n",
        "        y_train_num.append([0,0,1,0,0])\r\n",
        "    elif label == 'turkiye':\r\n",
        "        y_train_num.append([0,1,0,0,0])\r\n",
        "    elif label == 'video':\r\n",
        "        y_train_num.append([1,0,0,0,0])\r\n",
        "    else:\r\n",
        "        y_train_num.append([1,0,0,0,0])\r\n",
        "        print(\"LABEL IS NOT ONE OF THE FIVE !!\") \r\n",
        "\r\n",
        "y_test_num = []\r\n",
        "for label in y_test:\r\n",
        "    if label == 'spor':\r\n",
        "        y_test_num.append([0,0,0,0,1])\r\n",
        "    elif label == 'dunya':\r\n",
        "        y_test_num.append([0,0,0,1,0])\r\n",
        "    elif label == 'yazarlar':\r\n",
        "        y_test_num.append([0,0,1,0,0])\r\n",
        "    elif label == 'turkiye':\r\n",
        "        y_test_num.append([0,1,0,0,0])\r\n",
        "    elif label == 'video':\r\n",
        "        y_test_num.append([1,0,0,0,0])\r\n",
        "    else:\r\n",
        "        y_test_num.append([1,0,0,0,0])\r\n",
        "        print(\"LABEL IS NOT ONE OF THE FIVE !!\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bq5vSqoUlhm",
        "outputId": "9097cddb-82a4-454b-a314-beef851d43f4"
      },
      "source": [
        "np_y_train_num = numpy.array(y_train_num)\r\n",
        "np_y_test_num = numpy.array(y_test_num)\r\n",
        "print (\"Train : \",np_y_train_num)\r\n",
        "print(y_train)\r\n",
        "print(\"\\ntest: \", np_y_test_num)\r\n",
        "print(y_test)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train :  [[0 0 0 0 1]\n",
            " [0 0 1 0 0]\n",
            " [1 0 0 0 0]\n",
            " ...\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]]\n",
            "0           spor\n",
            "1       yazarlar\n",
            "2          video\n",
            "3          video\n",
            "4           spor\n",
            "          ...   \n",
            "7995        spor\n",
            "7996        spor\n",
            "7997       dunya\n",
            "7998       dunya\n",
            "7999       dunya\n",
            "Name: label, Length: 8000, dtype: object\n",
            "\n",
            "test:  [[1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " ...\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]]\n",
            "0          video\n",
            "1          dunya\n",
            "2          video\n",
            "3          video\n",
            "4       yazarlar\n",
            "          ...   \n",
            "1995        spor\n",
            "1996       dunya\n",
            "1997     turkiye\n",
            "1998    yazarlar\n",
            "1999        spor\n",
            "Name: label, Length: 2000, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "XWkZ_TP2EOuW",
        "outputId": "30df7811-a848-4ead-a75c-f2cf0ca7828c"
      },
      "source": [
        "\"\"\"import string\r\n",
        "#removing punctuation from the list\r\n",
        "X_train = [''.join(c for c in s if c not in string.punctuation) for s in X_train]\r\n",
        "df_train['text'] = X_train\r\n",
        "#print(df_train['text'])\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"import string\\n#removing punctuation from the list\\nX_train = [''.join(c for c in s if c not in string.punctuation) for s in X_train]\\ndf_train['text'] = X_train\\n#print(df_train['text'])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FQ-KajDEScy",
        "outputId": "fac68d0c-6d20-4502-a23a-f547d470172e"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOK832goEZMV"
      },
      "source": [
        "# Importing libraries\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers.convolutional import Conv1D\r\n",
        "from keras.layers.convolutional import MaxPooling1D\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.preprocessing import sequence\r\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oput33N0H6ho",
        "outputId": "e136f9b6-c8e4-49f5-83bf-9dfcce3b9bbd"
      },
      "source": [
        "#Maximum lenght of a document\r\n",
        "maxlen=-1\r\n",
        "corp = X_train\r\n",
        "for doc in corp:\r\n",
        "    tokens=nltk.word_tokenize(doc)\r\n",
        "    if(maxlen<len(tokens)):\r\n",
        "        maxlen=len(tokens)\r\n",
        "print(\"The maximum number of words in any document is : \",maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum number of words in any document is :  7974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOBZFlbG1lk"
      },
      "source": [
        "tokenizer = Tokenizer()\r\n",
        "tokenizer.fit_on_texts(X_train)\r\n",
        "\r\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\r\n",
        "\r\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqaY6A0tEbKa",
        "outputId": "bf19dd06-713a-4349-d1c4-286690139569"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) +1 \r\n",
        "print(\"Vocab size is:\", vocab_size)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size is: 206883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQIPBuaEHilP"
      },
      "source": [
        "#Padding using padding = 'pre'\r\n",
        "\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "X_train = pad_sequences(X_train, maxlen = maxlen) \r\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRTRL02zIdVr"
      },
      "source": [
        "# Building the CNN Model\r\n",
        "model = Sequential()      # initilaizing the Sequential nature for CNN model\r\n",
        "# Adding the embedding layer which will take in maximum of vocab_size words as input and provide a 50 dimensional output o\r\n",
        "\r\n",
        "model.add(Embedding(vocab_size, 50, input_length=maxlen))\r\n",
        "model.add(Conv1D(32, 5, activation='softmax'))\r\n",
        "model.add(MaxPooling1D())\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(250, activation='relu'))\r\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X89oD2WAI_ZL",
        "outputId": "61151bb6-5909-4206-b5e9-d4d7d3bb8e4a"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "#other loss option is sparse_categorical_crossentropy. Others do not fit."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 7974, 50)          10344150  \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 7970, 32)          8032      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 3985, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 127520)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               31880250  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 42,233,687\n",
            "Trainable params: 42,233,687\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iV0GyzeJDec",
        "outputId": "fe810435-ba8c-4c38-a3f9-d9babbbc844c"
      },
      "source": [
        "model.fit(X_train, np_y_train_num, validation_data=(X_test, np_y_test_num), epochs=12, batch_size=128, verbose=1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "63/63 [==============================] - 35s 551ms/step - loss: 0.7362 - acc: 0.7860 - val_loss: 0.9777 - val_acc: 0.6525\n",
            "Epoch 2/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.6672 - acc: 0.7900 - val_loss: 0.9522 - val_acc: 0.6545\n",
            "Epoch 3/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.6134 - acc: 0.7962 - val_loss: 0.9408 - val_acc: 0.6535\n",
            "Epoch 4/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.5718 - acc: 0.7950 - val_loss: 0.9271 - val_acc: 0.6515\n",
            "Epoch 5/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.5374 - acc: 0.7934 - val_loss: 0.9185 - val_acc: 0.6575\n",
            "Epoch 6/12\n",
            "63/63 [==============================] - 34s 548ms/step - loss: 0.5093 - acc: 0.7955 - val_loss: 0.9155 - val_acc: 0.6585\n",
            "Epoch 7/12\n",
            "63/63 [==============================] - 34s 548ms/step - loss: 0.4860 - acc: 0.8075 - val_loss: 0.9078 - val_acc: 0.6600\n",
            "Epoch 8/12\n",
            "63/63 [==============================] - 34s 548ms/step - loss: 0.4655 - acc: 0.8142 - val_loss: 0.9144 - val_acc: 0.6505\n",
            "Epoch 9/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.4488 - acc: 0.7974 - val_loss: 0.8965 - val_acc: 0.6380\n",
            "Epoch 10/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.4345 - acc: 0.8037 - val_loss: 0.9076 - val_acc: 0.6650\n",
            "Epoch 11/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.4227 - acc: 0.8136 - val_loss: 0.9093 - val_acc: 0.6625\n",
            "Epoch 12/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.4118 - acc: 0.8098 - val_loss: 0.9120 - val_acc: 0.6305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f683726a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx4CMFhRVlmg",
        "outputId": "ac4c4eb6-01cf-4c20-8607-6800769f7eb9"
      },
      "source": [
        "# Getting score metrics from our model\r\n",
        "scores = model.evaluate(X_test, np_y_test_num, verbose=0)\r\n",
        "# Displays the accuracy of correct sentiment prediction over test data\r\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\r\n",
        "\r\n",
        "#Scores[0] is loss, Scores[1] is accuracy \r\n",
        "print(scores)\r\n",
        "print(model.metrics_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 63.05%\n",
            "[0.91204833984375, 0.6305000185966492]\n",
            "['loss', 'acc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr2TEcV5vaYt"
      },
      "source": [
        "#Using pre-trained word embeddings\r\n",
        "\r\n",
        "from gensim import models\r\n",
        "link = 'https://drive.google.com/file/d/10I4dwHSiLZoShooCw4i68t3bFPYMIRqL/view?usp=sharing'\r\n",
        "download = drive.CreateFile({'id': '10I4dwHSiLZoShooCw4i68t3bFPYMIRqL'})\r\n",
        "download.GetContentFile('cs445_trmodel_p3')\r\n",
        "word2vec = models.KeyedVectors.load_word2vec_format('cs445_trmodel_p3', binary=True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5FoAVMbwxh6"
      },
      "source": [
        "#print(word2vec.most_similar(positive=[\"kral\",\"kadın\"],negative=[\"erkek\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpHaJyoc6pJE",
        "outputId": "6a894d8c-8927-45e3-8620-bb7511eec10c"
      },
      "source": [
        "# load embedding of gensim into keras model\r\n",
        "embedding = word2vec.wv.get_keras_embedding(train_embeddings=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwNn6LDF7awf",
        "outputId": "f8baa3d9-f5c3-4482-e930-125323afddce"
      },
      "source": [
        "model = Sequential()\r\n",
        "from keras.layers import GlobalMaxPooling1D\r\n",
        "model.add(embedding)\r\n",
        "model.add(Conv1D(32, 5, activation='softmax'))\r\n",
        "#model.add(MaxPooling1D())\r\n",
        "model.add(GlobalMaxPooling1D())\r\n",
        "model.add(Dense(250, activation='softmax'))\r\n",
        "model.add(Dense(5, activation='softmax'))\r\n",
        "# compile the model\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n",
        "# summarize the model\r\n",
        "print(model.summary())\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 400)         164982800 \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, None, 32)          64032     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 250)               8250      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 165,056,337\n",
            "Trainable params: 73,537\n",
            "Non-trainable params: 164,982,800\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQvDaiqs_BU6",
        "outputId": "4f480434-bcf9-4718-ca11-8c2eeed72005"
      },
      "source": [
        "# fit the model\r\n",
        "model.fit(X_train, np_y_train_num, validation_data=(X_test, np_y_test_num), epochs=12, batch_size=128, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "63/63 [==============================] - 35s 553ms/step - loss: 1.6075 - acc: 0.2276 - val_loss: 1.5953 - val_acc: 0.3110\n",
            "Epoch 2/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.5859 - acc: 0.3421 - val_loss: 1.5525 - val_acc: 0.4440\n",
            "Epoch 3/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.5363 - acc: 0.4572 - val_loss: 1.4880 - val_acc: 0.4685\n",
            "Epoch 4/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.4595 - acc: 0.5251 - val_loss: 1.4083 - val_acc: 0.5895\n",
            "Epoch 5/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.3634 - acc: 0.6414 - val_loss: 1.3143 - val_acc: 0.6200\n",
            "Epoch 6/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.2327 - acc: 0.6846 - val_loss: 1.2135 - val_acc: 0.6365\n",
            "Epoch 7/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 1.1126 - acc: 0.7213 - val_loss: 1.1431 - val_acc: 0.6520\n",
            "Epoch 8/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.9970 - acc: 0.7377 - val_loss: 1.0826 - val_acc: 0.6580\n",
            "Epoch 9/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.8961 - acc: 0.7638 - val_loss: 1.0223 - val_acc: 0.6675\n",
            "Epoch 10/12\n",
            "63/63 [==============================] - 34s 549ms/step - loss: 0.8120 - acc: 0.7716 - val_loss: 0.9908 - val_acc: 0.6650\n",
            "Epoch 11/12\n",
            "63/63 [==============================] - 35s 550ms/step - loss: 0.7342 - acc: 0.7832 - val_loss: 0.9663 - val_acc: 0.6720\n",
            "Epoch 12/12\n",
            "63/63 [==============================] - 35s 551ms/step - loss: 0.6716 - acc: 0.7956 - val_loss: 0.9355 - val_acc: 0.6780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f682f0160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}